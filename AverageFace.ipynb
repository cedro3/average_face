{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AverageFace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/average_face/blob/main/AverageFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da0RI5fOey1I"
      },
      "source": [
        "#テーマ：平均顔\n",
        "・扱える写真の種類は、**jpg**のみです。１人の顔が写っている写真を使用して下さい\\\n",
        "・画像のアップロード→顔画像の切り出し→ベクトル逆算→平均顔生成、という手順で行います\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho2S8T_yJv1Q"
      },
      "source": [
        "### 1.自分のPCをマシンに接続\n",
        "**右上にある接続ボタンをクリック　→　接続完了で緑色のチェックマーク表示**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuviq3qQkUFy",
        "cellView": "form"
      },
      "source": [
        "#@title 2.マシンにソフトをインストール（数分程度かかります）\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'encoder4editing'\n",
        "\n",
        "!git clone https://github.com/cedro3/average_face.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# 学習済みパラメータのダウンロード\n",
        "import os\n",
        "import gdown\n",
        "os.makedirs('pretrained_models', exist_ok=True)\n",
        "gdown.download('https://drive.google.com/u/1/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET', 'pretrained_models/e4e_ffhq_encode.pt', quiet=False)\n",
        "\n",
        "# ランドマークデータのダウンロード\n",
        "! wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "! bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# モデルに学習済みパラメータをロード\n",
        "model_path = 'pretrained_models/e4e_ffhq_encode.pt'  ####\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')\n",
        "\n",
        "\n",
        "# --- ライブラリーインポート＆関数定義 ---\n",
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "import PIL.Image\n",
        "import sys\n",
        "import bz2\n",
        "from keras.utils import get_file\n",
        "import dlib\n",
        "import argparse\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import projector\n",
        "import pretrained_networks\n",
        "from training import dataset\n",
        "from training import misc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "# -------------- フォルダー内画像表示 ---------------\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(40, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        img = Image.open(folder+'/'+file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        fig.tight_layout()\n",
        "        ax.set_xlabel(str(i+1), fontsize=30)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "# -------------- ベクトルから画像を生成・保存 -------------\n",
        "def vec2pic(vec_syn, dir):\n",
        "  \n",
        "    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'  \n",
        "    \n",
        "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = True \n",
        "    Gs_syn_kwargs.truncation_psi = 0.5\n",
        "\n",
        "    for i in range(len(vec_syn)):\n",
        "        vec = vec_syn[i].reshape(1,18,512)\n",
        "        image =  Gs.components.synthesis.run(vec, **Gs_syn_kwargs)        \n",
        "        img = PIL.Image.fromarray(image[0])\n",
        "        img.save(dir+str(i+1).zfill(3)+'.jpg') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPhT6pzgMmbq"
      },
      "source": [
        "### 3.左のウインドウを開く\n",
        "**左端のファイルシンボルをクリックし、encoder4editingフォルダーの先頭をクリックして開き、さらにその中のimagesフォルダーの先頭をクリックして開く**\\\n",
        "＊左のウインドウは実際と表示にタイムラグがあるので、必要に応じて左上にある更新ボタンを押す"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6VbFHu2YRAL"
      },
      "source": [
        "**------------- プログラム本体 --------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "algwWeLtKqeI"
      },
      "source": [
        "### 4.フォルダーを作成する\n",
        "**imagesフォルダーの右端の３つの点をクリックし、「新しいフォルダ」を選択**\\\n",
        "**適当なフォルダー名（例えば'test1'）を入力してリターン**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuzesTw3LVE5"
      },
      "source": [
        "### 5.自分の用意した顔画像（jpg）をアップロード\n",
        "**自分の作成したフォルダー（例えば'test1'）の右端の３つの点をクリックし、「アップロード」を選択**\\\n",
        "＊必ず、jpg画像を使って下さい。png画像では上手く行きません\\\n",
        "＊複数の画像を選択すると上手くアップロードできない場合は、まず１枚アップロードすると、その後複数でアップロードできます\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ld45KbIF45C",
        "cellView": "form"
      },
      "source": [
        "#@title 6.顔画像の切り出し（folderにフォルダー名を指定）\n",
        "\n",
        "folder = 'test1' #@param {type:\"string\"}\n",
        "path = './images/'+folder\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "if os.path.isdir('align'):\n",
        "     shutil.rmtree('align')\n",
        "os.makedirs('align', exist_ok=True)\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  import dlib\n",
        "  from utils.alignment import align_face\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor) \n",
        "  return aligned_image \n",
        "\n",
        "files = sorted(os.listdir(path))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = run_alignment(path+'/'+file)\n",
        "  input_image.resize((256,256))\n",
        "  input_image.save('./align/'+file)\n",
        "\n",
        "display_pic('align')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q8aDybUOjKQ"
      },
      "source": [
        "### 7.切り出した顔画像のチェック\n",
        "**6.で表示された画像が全て狙ったものになっているか確認し、上手く切り出せていない顔画像があれば4.に戻って再度進める**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxbCdavcfXNd",
        "cellView": "form"
      },
      "source": [
        "#@title 8.ベクトルの逆算\n",
        "if os.path.isdir('vec'):\n",
        "     shutil.rmtree('vec')\n",
        "os.makedirs('vec', exist_ok=True)\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "path = './align'\n",
        "files = sorted(os.listdir(path))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = Image.open(path+'/'+file)\n",
        "  transformed_image = img_transforms(input_image)\n",
        "  with torch.no_grad():\n",
        "     images, latents = net(transformed_image.unsqueeze(0).to('cuda').float(), randomize_noise=False, return_latents=True)\n",
        "     result_image, latent = images[0], latents[0]\n",
        "     torch.save(latents, './vec/'+file[:-4]+'.pt') # vec  保存\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxziK01TdkNU",
        "cellView": "form"
      },
      "source": [
        "#@title 9.平均顔の生成\n",
        "\n",
        "# フォルダー・リセット\n",
        "import os\n",
        "import shutil\n",
        "if os.path.isdir('vec_avg'):\n",
        "     shutil.rmtree('vec_avg')\n",
        "if os.path.isdir('vec_avg_pic'):\n",
        "     shutil.rmtree('vec_avg_pic')\n",
        "os.makedirs('vec_avg', exist_ok=True)\n",
        "os.makedirs('vec_avg_pic', exist_ok=True)\n",
        "\n",
        "# ベクトルの平均処理\n",
        "import glob \n",
        "files = glob.glob('./vec/*.pt')\n",
        "files.sort()\n",
        "\n",
        "avg = 0\n",
        "for i, file in enumerate(files):\n",
        "     latent = torch.load(file)\n",
        "     avg = (i*avg+latent)/(i+1)\n",
        "     torch.save(avg, './vec_avg/'+str(i+1).zfill(3)+'.pt') # ベクトルを保存\n",
        "     if i == 0:\n",
        "        result = avg\n",
        "     else:\n",
        "        result = torch.cat((result, avg),0)\n",
        "vec = result.to('cpu').detach().numpy().copy()\n",
        "\n",
        "vec_one = vec[-1].reshape(-1,18,512)\n",
        "\n",
        "# ベクトルから画像を生成し保存\n",
        "dir = 'vec_avg_pic/'\n",
        "vec2pic(vec_one, dir)\n",
        "\n",
        "# 保存した画像を表示\n",
        "display_pic('vec_avg_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8GplnUmQUsZ"
      },
      "source": [
        "### 10.平均顔のダウンロード\n",
        "**生成した平均顔は、vec_avg_picに001.jpgで保存されますので、右端の３つの点をクリックし、ダウンロードを選択**\\\n",
        "＊左のウインドウは実際と表示にタイムラグがあるので、必要に応じて左上にある更新ボタンを押す"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yway1ORZDC7"
      },
      "source": [
        "### 以下、4〜10の繰り返しです"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukNVwJnRPeNQ"
      },
      "source": [
        "### 【備考】\n",
        "・このノートを１回実行・終了してから、**すぐ再度実行**する場合は、前の記憶が不完全に残っていて上手く動かないことがあります\\\n",
        "・その場合は、右上にある**「ランタイム／ランタイムを出荷時設定にリセット」**をクリックしてから、最初から操作を行います"
      ]
    }
  ]
}