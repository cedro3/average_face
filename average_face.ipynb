{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "average_face",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cedro3/average_face/blob/main/average_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho2S8T_yJv1Q"
      },
      "source": [
        "## 1.セットアップ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuviq3qQkUFy"
      },
      "source": [
        "# --- e4e セットアップ ---\n",
        "import os\n",
        "os.chdir('/content')\n",
        "CODE_DIR = 'encoder4editing'\n",
        "\n",
        "!git clone https://github.com/cedro3/average_face.git $CODE_DIR\n",
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n",
        "os.chdir(f'./{CODE_DIR}')\n",
        "\n",
        "from argparse import Namespace\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append(\".\")\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from utils.common import tensor2im\n",
        "from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# 学習済みパラメータのダウンロード\n",
        "! pip install --upgrade gdown\n",
        "import os\n",
        "import gdown\n",
        "os.makedirs('pretrained_models', exist_ok=True)\n",
        "gdown.download('https://drive.google.com/u/1/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET', 'pretrained_models/e4e_ffhq_encode.pt', quiet=False)\n",
        "\n",
        "# ランドマークデータのダウンロード\n",
        "! wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
        "! bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n",
        "\n",
        "# モデルに学習済みパラメータをロード\n",
        "model_path = 'pretrained_models/e4e_ffhq_encode.pt'  ####\n",
        "ckpt = torch.load(model_path, map_location='cpu')\n",
        "opts = ckpt['opts']\n",
        "opts['checkpoint_path'] = model_path\n",
        "opts= Namespace(**opts)\n",
        "net = pSp(opts)\n",
        "net.eval()\n",
        "net.cuda()\n",
        "print('Model successfully loaded!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4pCQRNDlaAP"
      },
      "source": [
        "# --- ライブラリーインポート＆関数定義 ---\n",
        "%tensorflow_version 1.x\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import os\n",
        "import PIL.Image\n",
        "import sys\n",
        "import bz2\n",
        "from keras.utils import get_file\n",
        "import dlib\n",
        "import argparse\n",
        "import numpy as np\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import projector\n",
        "import pretrained_networks\n",
        "from training import dataset\n",
        "from training import misc\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "# -------------- フォルダー内画像表示 ---------------\n",
        "def display_pic(folder):\n",
        "    fig = plt.figure(figsize=(40, 40))\n",
        "    files = os.listdir(folder)\n",
        "    files.sort()\n",
        "    for i, file in enumerate(files):\n",
        "        img = Image.open(folder+'/'+file)    \n",
        "        images = np.asarray(img)\n",
        "        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "        image_plt = np.array(images)\n",
        "        ax.imshow(image_plt)\n",
        "        fig.tight_layout()\n",
        "        ax.set_xlabel(str(i+1), fontsize=30)               \n",
        "    plt.show()\n",
        "    plt.close()  \n",
        "\n",
        "# -------------- ベクトルから画像を生成・保存 -------------\n",
        "def vec2pic(vec_syn, dir):\n",
        "  \n",
        "    network_pkl = 'gdrive:networks/stylegan2-ffhq-config-f.pkl'  \n",
        "    \n",
        "    _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "    noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = True \n",
        "    Gs_syn_kwargs.truncation_psi = 0.5\n",
        "\n",
        "    for i in range(len(vec_syn)):\n",
        "        vec = vec_syn[i].reshape(1,18,512)\n",
        "        image =  Gs.components.synthesis.run(vec, **Gs_syn_kwargs)        \n",
        "        img = PIL.Image.fromarray(image[0])\n",
        "        img.save(dir+str(i).zfill(3)+'.jpg') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6oqf8JwzK0K"
      },
      "source": [
        "## 2.顔画像の切り出し\n",
        "・imagesフォルダーの画像から所定の位置に合わせて顔部分を切り出し、alignフォルダーに保存します\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vasMokvrH4sq"
      },
      "source": [
        "# 画像フォルダーの指定\n",
        "path = './images/sample1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ld45KbIF45C"
      },
      "source": [
        "# --- 顔画像の切り出し ---\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "if os.path.isdir('align'):\n",
        "     shutil.rmtree('align')\n",
        "os.makedirs('align', exist_ok=True)\n",
        "\n",
        "def run_alignment(image_path):\n",
        "  import dlib\n",
        "  from utils.alignment import align_face\n",
        "  predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
        "  aligned_image = align_face(filepath=image_path, predictor=predictor) \n",
        "  return aligned_image \n",
        "\n",
        "files = sorted(os.listdir(path))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = run_alignment(path+'/'+file)\n",
        "  input_image.resize((256,256))\n",
        "  input_image.save('./align/'+file)\n",
        "\n",
        "display_pic('align')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aktGPpopqca"
      },
      "source": [
        "## 3.ベクトルの逆算\n",
        "・alignフォルダーの画像からベクトルを逆算し、ベクトルをvecフォルダーに、そのベクトルから生成した画像をvec_picフォルダーへ保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxbCdavcfXNd"
      },
      "source": [
        "# ------ ベクトルの逆算 ------\n",
        "\n",
        "# フォルダーリセット\n",
        "if os.path.isdir('vec_pic'):\n",
        "     shutil.rmtree('vec_pic')\n",
        "os.makedirs('vec_pic', exist_ok=True)\n",
        "\n",
        "if os.path.isdir('vec'):\n",
        "     shutil.rmtree('vec')\n",
        "os.makedirs('vec', exist_ok=True)\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "path = './align'\n",
        "files = sorted(os.listdir(path))\n",
        "for i, file in enumerate(tqdm(files)):\n",
        "  if file=='.ipynb_checkpoints':\n",
        "     continue\n",
        "  input_image = Image.open(path+'/'+file)\n",
        "  transformed_image = img_transforms(input_image)\n",
        "  with torch.no_grad():\n",
        "     images, latents = net(transformed_image.unsqueeze(0).to('cuda').float(), randomize_noise=False, return_latents=True)\n",
        "     result_image, latent = images[0], latents[0]\n",
        "     tensor2im(result_image).save('./vec_pic/'+file) # vec_pic 保存\n",
        "     torch.save(latents, './vec/'+file[:-4]+'.pt') # vec  保存\n",
        "\n",
        "display_pic('vec_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxWYxEBGqWEC"
      },
      "source": [
        "## 4.ベクトルの平均処理\n",
        "・vecフォルダーのベクトルを平均し、ベクトルをvec_avgに、画像をvec_avg_picに保存します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxziK01TdkNU"
      },
      "source": [
        "# -----------  ベクトルの平均処理 ---------\n",
        "\n",
        "# フォルダー・リセット\n",
        "import os\n",
        "import shutil\n",
        "if os.path.isdir('vec_avg'):\n",
        "     shutil.rmtree('vec_avg')\n",
        "if os.path.isdir('vec_avg_pic'):\n",
        "     shutil.rmtree('vec_avg_pic')\n",
        "os.makedirs('vec_avg', exist_ok=True)\n",
        "os.makedirs('vec_avg_pic', exist_ok=True)\n",
        "\n",
        "# ベクトルの平均処理\n",
        "import glob \n",
        "files = glob.glob('./vec/*.pt')\n",
        "files.sort()\n",
        "\n",
        "avg = 0\n",
        "for i, file in enumerate(files):\n",
        "     latent = torch.load(file)\n",
        "     avg = (i*avg+latent)/(i+1)\n",
        "     torch.save(avg, './vec_avg/'+str(i).zfill(3)+'.pt') # ベクトルを保存\n",
        "     if i == 0:\n",
        "        result = avg\n",
        "     else:\n",
        "        result = torch.cat((result, avg),0)\n",
        "vec = result.to('cpu').detach().numpy().copy()\n",
        "\n",
        "# ベクトルから画像を生成し保存\n",
        "dir = 'vec_avg_pic/'\n",
        "vec2pic(vec, dir)\n",
        "\n",
        "# 保存した画像を表示\n",
        "display_pic('vec_avg_pic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymlZBipir4gb"
      },
      "source": [
        "## 5.平均画像の収束状況\n",
        "・1〜N枚目の平均ベクトルと１枚目のベクトルのCOS類似度の関係を見る"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfQoY9fNzXdv"
      },
      "source": [
        "# --- 平均画像の収束状況確認 ---\n",
        "value = []\n",
        "for k in range(len(vec)):\n",
        "    result = 0\n",
        "    for i in range(18):\n",
        "        cos = np.dot(vec[k,i],vec[0,i])/(np.linalg.norm(vec[k,i])*np.linalg.norm(vec[0,i]))\n",
        "        result = result + cos/18\n",
        "    value.append(result)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(value)\n",
        "plt.ylabel('cos similarity')\n",
        "plt.xlabel('N')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u73VKvk3rGAf"
      },
      "source": [
        "## 6.顔画像の多様性指数\n",
        "・vecフォルダーのベクトルから平均ベクトルを計算し、各ベクトルと平均ベクトルとのCOS類似度から、顔画像の多様性指数を計算する。数値が大きいほど多様性が大きい。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ii5C99aLAM"
      },
      "source": [
        "# -------- 多様性指数 ----------\n",
        "\n",
        "# ベクトルの読み込み\n",
        "import glob\n",
        "files = glob.glob('vec/*.pt')\n",
        "files.sort()\n",
        "\n",
        "for i, file in enumerate(files):\n",
        "    z = torch.load(file)\n",
        "    if i == 0:\n",
        "       vec = z\n",
        "    else:\n",
        "       vec = torch.cat((vec, z),0)\n",
        "\n",
        "# 平均ベクトル計算（18, 512）\n",
        "avg = 0\n",
        "for i in range(len(vec)):\n",
        "    avg = avg + vec[i]\n",
        "avg = avg/len(vec)\n",
        "\n",
        "# 各ベクトルと平均ベクトルのCOS類似度計算\n",
        "var = 0\n",
        "for i in range(len(vec)):\n",
        "    tmp = torch.cosine_similarity(vec[i],avg)  # vec[i]と平均ベクトルとのCOS類似度\n",
        "    tmp = torch.sum(tmp[2:8])/6  # 3〜8番目のみの平均をとる\n",
        "    tmp = tmp.item()  # テンソルから数字を取り出す\n",
        "    var = var + tmp\n",
        "var = var/len(vec)  \n",
        "var = 1 - var # 数値が大きいほど多様性が大きいにする\n",
        "print('variance = ',var)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57dJiX11E_k9"
      },
      "source": [
        "## 7.女性成分、男性成分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ie3sWlJUMZ"
      },
      "source": [
        "# -------- 女性成分、男性成分 -------\n",
        "\n",
        "# フォルダーリセット\n",
        "import os\n",
        "import shutil\n",
        "if os.path.isdir('calc'):\n",
        "     shutil.rmtree('calc')\n",
        "os.makedirs('calc', exist_ok=True)\n",
        "dir = 'calc/'\n",
        "\n",
        "# 平均顔ベクトルの読み込み\n",
        "x1 = torch.load('./sample/vector/1.pt')  # アジア系女性20人の平均顔\n",
        "x2 = torch.load('./sample/vector/2.pt')  # アジア系女性10人＋欧米系女性10人の平均顔\n",
        "x3 = torch.load('./sample/vector/3.pt')  # アジア系男性20人の平均顔\n",
        "x4 = torch.load('./sample/vector/4.pt')  # アジア系男性10人＋欧米系男性10人の平均顔\n",
        "x5 = torch.load('./sample/vector/5.pt')  # ミス・ジャパン35人の平均顔\n",
        "x6 = torch.load('./sample/vector/6.pt')  # ミスター・ジャパン20人の平均顔\n",
        "x7 = torch.load('./sample/vector/7.pt')  # ミス・インターナショナル30人の平均顔\n",
        "\n",
        "# ベクトル演算\n",
        "# ----------------------\n",
        "z1 = x2 + (x2 - x4)*0.3  # 女性化＋30%\n",
        "z2 = x2 + (x2 - x4)*0.5  # 女性化＋50%\n",
        "z3 = x2 + (x2 - x4)*1.0  # 女性化＋100%\n",
        "z = torch.cat((x2, z1, z2, z3), 0)  # （元画像, +30%, +50%, +100%）を表示\n",
        "# ---------------------\n",
        "\n",
        "z = z.to('cpu').detach().numpy().copy()\n",
        "vec2pic(z, dir)\n",
        "display_pic(dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g02h0obT7n7G"
      },
      "source": [
        "# 8.美人度\n",
        "・vecに保存されているベクトルとミス・インターナショナルの平均顔ベクトルとのCOS類似度を計算します"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqpT3K6vHrPh"
      },
      "source": [
        "# -------- 美人度 -----------\n",
        "\n",
        "# ベクトルの読み込み\n",
        "import glob\n",
        "files = glob.glob('vec/*.pt')\n",
        "files.sort()\n",
        "\n",
        "for i, file in enumerate(files):\n",
        "    z = torch.load(file)\n",
        "    if i == 0:\n",
        "       vec = z\n",
        "    else:\n",
        "       vec = torch.cat((vec, z),0)\n",
        "\n",
        "# 基準ベクトルの読み込み\n",
        "max = torch.load('./sample/vector/7.pt')  # ミス・インターナショナル30人の平均顔\n",
        "\n",
        "\n",
        "# 美人度計算（各ベクトルと基準ベクトルとのCOS類似度）\n",
        "for i in range(len(vec)):\n",
        "    tmp = torch.cosine_similarity(vec[i],max[0])  # vec[i]と基準ベクトルとのCOS類似度\n",
        "    tmp = torch.sum(tmp[2:8])/6  # 3〜8番目のみの平均をとる\n",
        "    tmp = tmp.item()  # テンソルから数字を取り出す\n",
        "    print(i+1, tmp)  # 各人のCOS類似度を表示"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
